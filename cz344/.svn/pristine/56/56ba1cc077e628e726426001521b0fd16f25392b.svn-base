function tokenizedata(directory,output)

if nargin<1,directory='data_train';end;
if nargin<2,output='data_train';end;

%% tokenization (X)

% Uncomment these lines if you want to do tokenization yourself

fprintf('Running python tokenization script ...\n');
system(['python tokenize.py ' directory ' 11 > spamdata.csv']);
fprintf('Loading data ...\n');
M=load('spamdata.csv');

% Load in labels (do not change this part of the code)
%[label,paths]=textread([directory '/index'],'%s %s');
%Y=cellfun(@(x) isequal(x,'spam')*2-1,label,'UniformOutput',true)';    
%clear('label');

% normalize the colums to sum to 1
X=sparse(M(:,2),M(:,1),ones(length(M),1));
%num_spam = sum(Y~=-1);
%num_ham = sum(Y~=1);
%temp = X;
%[d,n]=size(temp);
%temp_spam = X(:,Y~=-1);
%temp_ham = X(:,Y~=1);
%vector_idf=log(abs((num_spam./sum(temp_spam~=0,2))-(num_ham./sum(temp_ham~=0,2)))+1);
%idf=repmat(vector_idf,1,n);

temp = X;
[d,n]=size(temp);
vector_idf=log2((n./(sum(temp~=0,2))+1));
idf=repmat(vector_idf,1,n);
X=X*(spdiags(1./sum(X)',0,size(X,2),size(X,2)));
X=X.*idf;

clear('M');

% Load in labels (do not change this part of the code)
[label,paths]=textread([directory '/index'],'%s %s');
Y=cellfun(@(x) isequal(x,'spam')*2-1,label,'UniformOutput',true)';    
clear('label');

save([output '.mat'],'X','Y');




